{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e50102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Status: Running on Google Colab\n",
      "Dataset Loaded: 5000 rows, 22 columns\n",
      "Data Preprocessing Complete:\n",
      "- Rows removed as outliers: 30\n",
      "- Rows kept for core analysis: 4970\n",
      "- Salary range for analysis: $15,321 to $149,448\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Strategic Workforce Analysis: AI Integration vs. Structural Risk (2010-2025)\n",
    "# ## Task 1: Data Preprocessing & Outlier Handling\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Environment Detection for Data Path ---\n",
    "# Logic to handle both Google Colab Drive and Local file system\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = '/content/drive/MyDrive/ai_impact_jobs_2010_2025.csv'\n",
    "    print(\"Status: Running on Google Colab\")\n",
    "except:\n",
    "    DATA_PATH = '../data/raw/ai_impact_jobs_2010_2025.csv'\n",
    "    print(\"Status: Running on Local Environment\")\n",
    "\n",
    "# %%\n",
    "# 1. Load Dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset Loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# 2. Basic Cleaning\n",
    "# Handling missing values for categorical columns to prevent errors in grouping\n",
    "df['ai_skills'] = df['ai_skills'].fillna('Not Specified')\n",
    "df['ai_keywords'] = df['ai_keywords'].fillna('None')\n",
    "\n",
    "# 3. IQR-based Outlier Removal for Salary\n",
    "# We use IQR to focus our analysis on the mainstream market behavior\n",
    "Q1 = df['salary_usd'].quantile(0.25)\n",
    "Q3 = df['salary_usd'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_limit = Q1 - 1.5 * IQR\n",
    "upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtering the data\n",
    "df_cleaned = df[(df['salary_usd'] >= lower_limit) & (df['salary_usd'] <= upper_limit)].copy()\n",
    "df_outliers = df[df['salary_usd'] > upper_limit].copy()\n",
    "\n",
    "print(f\"Data Preprocessing Complete:\")\n",
    "print(f\"- Rows removed as outliers: {len(df_outliers)}\")\n",
    "print(f\"- Rows kept for core analysis: {len(df_cleaned)}\")\n",
    "print(f\"- Salary range for analysis: ${df_cleaned['salary_usd'].min():,.0f} to ${df_cleaned['salary_usd'].max():,.0f}\")\n",
    "\n",
    "# %%\n",
    "# 4. Save the Cleaned Dataset for subsequent tasks\n",
    "# We save this to ensure consistency across all analysis branches\n",
    "PROCESSED_DATA_PATH = '../data/processed/ai_impact_jobs_cleaned.csv'\n",
    "\n",
    "df_cleaned.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "\n",
    "print(f\"ðŸ’¾ Cleaned dataset saved to: {PROCESSED_DATA_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
