{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30e50102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 Success! Cleaned data saved at: /Users/miraekang/proyectos/eda/data/processed/ai_impact_jobs_cleaned.csv\n",
      "Final Columns Check: ['job_id', 'posting_year', 'country', 'region', 'city', 'company_name', 'company_size', 'industry', 'job_title', 'seniority_level', 'ai_mentioned', 'ai_keywords', 'ai_intensity_score', 'core_skills', 'ai_skills', 'salary_usd', 'salary_change_vs_prev_year_percent', 'automation_risk_score', 'reskilling_required', 'ai_job_displacement_risk', 'job_description_embedding_cluster', 'industry_ai_adoption_stage']\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Strategic Workforce Analysis: AI Integration vs. Structural Risk (2010-2025)\n",
    "# ## Task 1: Data Preprocessing & Outlier Handling\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- 1. Robust Path Setup ---\n",
    "# Get current working directory (notebooks) and move to parent to find data/\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "RAW_DATA_PATH = os.path.join(BASE_DIR, 'data', 'raw', 'ai_impact_jobs_2010_2025.csv')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "\n",
    "# Ensure folder exists\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# 2. Load Dataset\n",
    "df = pd.read_csv(RAW_DATA_PATH)\n",
    "\n",
    "# 3. Data Cleaning (Nulls)\n",
    "df['ai_skills'] = df['ai_skills'].fillna('Not Specified')\n",
    "df['ai_keywords'] = df['ai_keywords'].fillna('None')\n",
    "\n",
    "# 4. NESTED IQR LOGIC (The \"Flower\" of the project)\n",
    "# We calculate IQR for each (Region + Seniority) group to remove local anomalies.\n",
    "cleaned_chunks = []\n",
    "\n",
    "# Get all unique combinations of Region and Seniority\n",
    "for region in df['region'].unique():\n",
    "    for level in df['seniority_level'].unique():\n",
    "        # Create a subset\n",
    "        subset = df[(df['region'] == region) & (df['seniority_level'] == level)]\n",
    "        \n",
    "        if len(subset) > 3: # Only clean if we have enough data\n",
    "            q1 = subset['salary_usd'].quantile(0.25)\n",
    "            q3 = subset['salary_usd'].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower = q1 - 1.5 * iqr\n",
    "            upper = q3 + 1.5 * iqr\n",
    "            # Filter the subset\n",
    "            subset = subset[(subset['salary_usd'] >= lower) & (subset['salary_usd'] <= upper)]\n",
    "        \n",
    "        cleaned_chunks.append(subset)\n",
    "\n",
    "# Combine everything back - Columns are guaranteed to stay\n",
    "df_cleaned = pd.concat(cleaned_chunks).reset_index(drop=True)\n",
    "\n",
    "# 5. Save the Cleaned Dataset\n",
    "CLEANED_FILE_PATH = os.path.join(PROCESSED_DIR, 'ai_impact_jobs_cleaned.csv')\n",
    "df_cleaned.to_csv(CLEANED_FILE_PATH, index=False)\n",
    "\n",
    "print(f\"Task 1 Success! Cleaned data saved at: {CLEANED_FILE_PATH}\")\n",
    "print(f\"Final Columns Check: {df_cleaned.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Task 2: Establishing the Salary Baseline (Q1)\n",
    "# **Objective:** To define the global salary standard and identify regional variations.\n",
    "\n",
    "# %%\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define path again for safety\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "CLEANED_FILE_PATH = os.path.join(BASE_DIR, 'data', 'processed', 'ai_impact_jobs_cleaned.csv')\n",
    "\n",
    "# Load the clean data\n",
    "df_cleaned = pd.read_csv(CLEANED_FILE_PATH)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2.1 The Global Distribution (Post-Nested IQR)\n",
    "# **Story:** After removing localized outliers, we observe the \"True Market Range\". \n",
    "# This represents the stable economic floor for the global AI workforce.\n",
    "\n",
    "# %%\n",
    "fig1 = px.histogram(df_cleaned, x=\"salary_usd\", marginal=\"box\",\n",
    "                   title=\"<b>Graph 1: Global Salary Baseline - Mainstream Market Range</b>\",\n",
    "                   labels={'salary_usd': 'Salary (USD)'},\n",
    "                   color_discrete_sequence=['#27ae60'], \n",
    "                   template=\"plotly_white\")\n",
    "fig1.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2.2 The Locality Paradox: North America vs. South Asia\n",
    "# **Question:** Why did our global seniority analysis look \"flat\" earlier? \n",
    "# **Result:** As shown below, an Intern in North America often earns more than a Senior in South Asia. \n",
    "# **Story:** The \"Where\" (Region) is currently a stronger salary driver than \"Who\" (Seniority).\n",
    "\n",
    "# %%\n",
    "# Comparing two extreme markets to tell a story\n",
    "target_regions = ['North America', 'South Asia']\n",
    "df_comparison = df_cleaned[df_cleaned['region'].isin(target_regions)]\n",
    "\n",
    "fig2 = px.box(df_comparison, x=\"seniority_level\", y=\"salary_usd\", color=\"region\",\n",
    "             category_orders={\"seniority_level\": [\"Intern\", \"Junior\", \"Mid\", \"Senior\", \"Lead\", \"Executive\"]},\n",
    "             title=\"<b>Graph 2: Market Maturity Gap - North America vs. South Asia</b>\",\n",
    "             labels={'salary_usd': 'Annual Salary (USD)', 'seniority_level': 'Seniority Level'},\n",
    "             template=\"simple_white\")\n",
    "\n",
    "fig2.update_layout(boxmode='group')\n",
    "fig2.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# **Strategic Bridge:** \n",
    "# If regional geography dictates the baseline, can **AI Intensity** be the catalyst that breaks this geographic barrier? \n",
    "# In Task 3, we will analyze the ROI of AI Integration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eda-uv)",
   "language": "python",
   "name": "eda-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
